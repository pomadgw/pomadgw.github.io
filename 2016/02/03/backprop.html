<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title>Cobaan! — pomadgw's blog</title> <meta name="description" content="I’m doing coding an implementation of an fully connected, multi–layeredfeed–forward neural network. I tried to implement backpropagation algorithm as see inR..."> <script type="text/javascript" src="http://fast.fonts.net/jsapi/562f66c8-64b2-4c52-a829-84707a730c7a.js"></script> <link rel="stylesheet" href="/css/styles.css"> <link href="/css/print.css" media="print" rel="stylesheet" type="text/css" /> <link rel="canonical" href="http://pomadgw.github.io/2016/02/03/backprop.html"> <link rel="alternate" type="application/rss+xml" title="pomadgw's blog" href="http://pomadgw.github.io/feed.xml"> <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: {inlineMath: [['!$','$!'], ['\\(','\\)']]} }); </script> <script type="text/javascript" async src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_SVG"></script> </head> <body> <div class="container main-data" id="main-data"> <header class="site-header"> <nav class="navbar navbar-light bg-faded"> <div class="nav-header"> <button class="pull-xs-left navbar-toggler hidden-sm-up" type="button" data-toggle="collapse" data-target="#collapse-nav"> &#9776; </button> <a class="navbar-brand" href="/">pomadgw's blog</a> <div class="clearfix"></div> </div> <div class="collapse navbar-toggleable-xs" id="collapse-nav"> <ul class="nav navbar-nav"> <li class="nav-item "> <a class="nav-link" href="/about-me/">About<span class="sr-only">(current)</span></a> </li> </ul> <form class="form-inline pull-md-right" id="site_search" action="/search.html"> <input class="form-control" type="text" id="search_box" name="q" placeholder="Search"> <button class="btn btn-default" type="submit">Search</button> </form> </div> </nav> </header> <div class="container-fluid bg-header-intro-img" > </div> <div class="wrapper-text notindex"> <div class="row"> <div class="col-xs-12"> <article class="post" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header header"> <h1 class="post-title" itemprop="name headline">Cobaan!</h1> <p class="post-meta"><time datetime="2016-02-03T14:49:00+07:00" itemprop="datePublished"> 3 <a href="/2016/02">February</a> <a href="/2016/">2016</a> </time> • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Rahadian Yusuf</span></span></p> </header> <div class="post-content" itemprop="articleBody"> <p>I’m doing coding an implementation of an fully connected, multi–layered feed–forward neural network. I tried to implement backpropagation algorithm as see in Russell and Norvig’s <em>Artificial Intelligence: A Modern Approach</em> while using matrix as internal weight representation.</p> <!-- more --> <p>Here is the matrix representation of the weight for one layer:</p> <script type="math/tex; mode=display">% <![CDATA[ W_t = \begin{pmatrix} w_{0,1} & w_{0,2} & \cdots & w_{0,k} \\ w_{1,1} & w_{1,2} & \cdots & w_{1,k} \\ w_{2,1} & w_{2,2} & \cdots & w_{2,k} \\ \vdots & \vdots & \ddots & \vdots \\ w_{j,1} & w_{j,2} & \cdots & w_{j,k} \end{pmatrix} %]]></script> <p>In !$W_t$!, let we define !$w_{j,k}$! as weight of connection from unit !$j$! to unit !$k$!. I added additional row for keeping weight of biased value !$w_{0,k}$!.</p> <p>To get the output of unit !$k$!, first we get the weighted sum of its inputs:</p> <script type="math/tex; mode=display">in_k = \sum_{j = 0}^{n}w_{j,k}a_j</script> <p>Then, we derive the output of the unit by passing the sum to an activation function:</p> <script type="math/tex; mode=display">a_k = g(in_k) = g\left(\sum_{j = 0}^{n}w_{j,k}a_j\right)</script> <p>Now, how could I get the output vector !$\vec{o}$! given input vector !$\vec{a}$! and weight matrix !$W$!?</p> <p>Let matrix for input M:</p> <script type="math/tex; mode=display">% <![CDATA[ \begin{align} M & = \begin{pmatrix} w_{0,1}a_0 & w_{0,2}a_0 & \cdots & w_{0,k}a_0 \\ w_{1,1}a_1 & w_{1,2}a_1 & \cdots & w_{1,k}a_1 \\ \vdots & \vdots & \ddots & \vdots \\ w_{j,1}a_j & w_{j,2}a_j & \cdots & w_{j,k}a_j \end{pmatrix} \end{align} %]]></script> <p>where element of !$M$!, !$m_{j,k}$!:</p> <script type="math/tex; mode=display">m_{j,k} = w_{j,k}a_j</script> <p>with dummy input !$a_0 = 1$! with associated weight !$w_{0,j}$!.</p> <p>Now, let function !$\Phi$!:</p> <script type="math/tex; mode=display">\Phi(\phi) = e^\intercal\phi</script> <p>where !$e$! is row vector of ones, or !$e = (1, 1, \cdots, 1)$!.</p> <p>Now, to get vectors of weighted input !$\vec{in}$!:</p> <script type="math/tex; mode=display">\vec{in} = \Phi(M)</script> <p>Simple.</p> <p>Now, I want matrix of inputs !$A$! such as:</p> <script type="math/tex; mode=display">AW_t = M</script> <p>Let’s see…</p> <script type="math/tex; mode=display">% <![CDATA[ \begin{align} AW_t & = M \\ A \begin{pmatrix} w_{0,1} & w_{0,2} & \cdots & w_{0,k} \\ w_{1,1} & w_{1,2} & \cdots & w_{1,k} \\ w_{2,1} & w_{2,2} & \cdots & w_{2,k} \\ \vdots & \vdots & \ddots & \vdots \\ w_{j,1} & w_{j,2} & \cdots & w_{j,k} \end{pmatrix} & = \begin{pmatrix} w_{0,1}a_0 & w_{0,2}a_0 & \cdots & w_{0,k}a_0 \\ w_{1,1}a_1 & w_{1,2}a_1 & \cdots & w_{1,k}a_1 \\ \vdots & \vdots & \ddots & \vdots \\ w_{j,1}a_j & w_{j,2}a_j & \cdots & w_{j,k}a_j \end{pmatrix} \end{align} %]]></script> <p>Now, let’s see the rule of weight–update for network with !$i$! input units, !$j$! hidden units, and !$k$! output unit. For connections between hidden units and output units:</p> <script type="math/tex; mode=display">w_{j,k} \leftarrow w_{j,k} + \alpha \times a_j \times \Delta_k</script> <p>where</p> <script type="math/tex; mode=display">\Delta_k = Err_k \times g'(in_k)</script> <p>For connections between input units and hidden units:</p> <script type="math/tex; mode=display">w_{i,j} \leftarrow w_{i,j} + \alpha \times a_i \times \Delta_j</script> <p>where</p> <script type="math/tex; mode=display">\Delta_j = g'(in_j) \times \sum_{k}w_{j,k}\Delta_k</script> <p>As you note, the weight–update rule for connections between input units and hidden units with update rule for output units is identical—it differ only in definition of !$\Delta$!.</p> <p>Now, I will put these into matrix for updated weight matrix !$W_{t+1}$!:</p> <div class="table-responsive smaller-math"> $$ \begin{align} W_{t+1} &amp; = \begin{pmatrix} w_{1,1} + \alpha \times a_1 \times \Delta_1 &amp; w_{1,2} + \alpha \times a_1 \times \Delta_2 &amp; \cdots &amp; w_{1,k} + \alpha \times a_1 \times \Delta_k \\ w_{2,1} + \alpha \times a_2 \times \Delta_1 &amp; w_{2,2} + \alpha \times a_2 \times \Delta_2 &amp; \cdots &amp; w_{2,k} + \alpha \times a_2 \times \Delta_k \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ w_{j,1} + \alpha \times a_j \times \Delta_1 &amp; w_{j,2} + \alpha \times a_j \times \Delta_2 &amp; \cdots &amp; w_{j,k} + \alpha \times a_j \times \Delta_k \\ w_{bias,1} + \alpha \times -1 \times \Delta_1 &amp; w_{bias,2} + \alpha \times -1 \times \Delta_2 &amp; \cdots &amp; w_{bias,k} + \alpha \times -1 \times \Delta_k \\ \end{pmatrix} \\ &amp; = \begin{pmatrix} w_{1,1} &amp; w_{1,2} &amp; \cdots &amp; w_{1,k} \\ w_{2,1} &amp; w_{2,2} &amp; \cdots &amp; w_{2,k} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ w_{j,1} &amp; w_{j,2} &amp; \cdots &amp; w_{j,k} \\ w_{bias,1} &amp; w_{bias,2} &amp; \cdots &amp; w_{bias,k} \end{pmatrix} + \begin{pmatrix} \alpha \times a_1 \times \Delta_1 &amp; \alpha \times a_1 \times \Delta_2 &amp; \cdots &amp; \alpha \times a_1 \times \Delta_k \\ \alpha \times a_2 \times \Delta_1 &amp; \alpha \times a_2 \times \Delta_2 &amp; \cdots &amp; \alpha \times a_2 \times \Delta_k \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \alpha \times a_j \times \Delta_1 &amp; \alpha \times a_j \times \Delta_2 &amp; \cdots &amp; \alpha \times a_j \times \Delta_k \\ \alpha \times -1 \times \Delta_1 &amp; \alpha \times -1 \times \Delta_2 &amp; \cdots &amp; \alpha \times -1 \times \Delta_k \\ \end{pmatrix} \\ &amp; = W_t + \alpha \times \begin{pmatrix} a_1 \times \Delta_1 &amp; a_1 \times \Delta_2 &amp; \cdots &amp; a_1 \times \Delta_k \\ a_2 \times \Delta_1 &amp; a_2 \times \Delta_2 &amp; \cdots &amp; a_2 \times \Delta_k \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ a_j \times \Delta_1 &amp; a_j \times \Delta_2 &amp; \cdots &amp; a_j \times \Delta_k \\ -\Delta_1 &amp; -\Delta_2 &amp; \cdots &amp; -\Delta_k \\ \end{pmatrix} \\ &amp; = W_t + \alpha \times \begin{pmatrix} a_1 \\ a_2 \\ \vdots \\ a_j \\ -1 \end{pmatrix} \times \begin{pmatrix} \Delta_1 &amp; \Delta_2 &amp; \cdots &amp; \Delta_k \end{pmatrix} \end{align} $$ </div> </div> <div> In <a class="tag" href="/tags/kuliah">kuliah</a> <a class="tag" href="/tags/college">college</a> </div> </article> </div> <div class="col-xs-12"> <footer class="site-footer"> <div class="wrapper"> <h2 class="footer-heading">pomadgw's blog</h2> <div class="footer-col-wrapper"> <div class="footer-col footer-col-3"> <p>This is my blog at github; </p> </div> <div class="footer-col footer-col-2"> <div class="row social-media-list"> <div class="col-sm-6"> <a href="https://github.com/pomadgw"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg> </span><span class="username">pomadgw</span></a> </div> <div class="col-sm-6"> <a href="https://twitter.com/RianYusuf94"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg> </span><span class="username">RianYusuf94</span></a> </div> </div> </div> </div> </div> </footer> </div> <footer class="text-xs-center credit"> &copy; 2016. Rahadian Yusuf. </footer> </div> </div> </div> <!-- SCRIPT HERE --> <script src="/js/bootstrap.min.js"></script> <!-- <script src="/js/highlight.pack.js"></script> --> <script src="/js/FileSaver.js"></script> <script src="/js/scripts.js"></script> <script src="/js/smartquotes.min.js"></script> </body> </html>
